{
 "metadata": {
  "name": "",
  "signature": "sha256:e9cdefcf50c2cf43bb665920095c54a6cb48bc1a433c1cdbebf926b3be90d028"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import simplejson as json\n",
      "import os\n",
      "import string\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "import tweepy\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "\n",
      "import model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEXT = []\n",
      "LABELS = []\n",
      "\n",
      "data = model.Status.get_all_statuses()\n",
      "for status in data:\n",
      "    TEXT.append(status.text.lower())\n",
      "    #label 'p' for political\n",
      "    if status.label == \"p\":\n",
      "        LABELS.append(\"p\")\n",
      "    else:\n",
      "        LABELS.append(\"np\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"TEXT LEN:\", len(TEXT)\n",
      "print \"LABELS LEN:\", len(LABELS)\n",
      "print TEXT[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TEXT LEN: 48787\n",
        "LABELS LEN: 48787\n",
        "@npr--reconsider gutting @nprscience: we need more climate coverage! (i  pledge @ kqed-fm.) http://t.co/vxpwc8wqlr via @credomobile #p2\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ENGLISH_STOP_WORDS = [\n",
      "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
      "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
      "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
      "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
      "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
      "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
      "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
      "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
      "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
      "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
      "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
      "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n",
      "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
      "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
      "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
      "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
      "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
      "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
      "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
      "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
      "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
      "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
      "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
      "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
      "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
      "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
      "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
      "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
      "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
      "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
      "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
      "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
      "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
      "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
      "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
      "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
      "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
      "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
      "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
      "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
      "    \"yourselves\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops = ['http', 'rt']\n",
      "stops.extend(ENGLISH_STOP_WORDS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "makeVector = TfidfVectorizer(analyzer=\"word\", stop_words=stops)\n",
      "print makeVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=['http', 'rt', 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', '...ill', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves'],\n",
        "        strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create vector from raw documents (X)\n",
      "X = makeVector.fit_transform(TEXT)\n",
      "print X.shape\n",
      "# print X\n",
      "\n",
      "# create numpy array of labels\n",
      "# numpy arrays = n-dimensional array with collection of items all the same type. Homogenous.\n",
      "y = np.array(LABELS)\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(48787, 76799)\n",
        "(48787,)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fraction_np(text_list, label_list):\n",
      "    \"\"\"\n",
      "    Get fraction of training data that is associated with \"np\" (nonpolitical)\n",
      "    label.\n",
      "    \"\"\"\n",
      "    # get number of nonpolitical\n",
      "    np_list = [label for label in label_list if label == 'np']\n",
      "    \n",
      "#     print len(text_list)\n",
      "#     print len(np_list)\n",
      "    \n",
      "    return float(len(np_list))/float(len(text_list))\n",
      "\n",
      "print get_fraction_np(TEXT, LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.723225449403\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LogisticRegression(class_weight = \"auto\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X, y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Kfolds = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = cross_validation.StratifiedKFold(y, Kfolds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision = []\n",
      "recall = []\n",
      "\n",
      "for train, test in cv:\n",
      "    X_train = X[train]\n",
      "    X_test = X[test]\n",
      "    y_train = y[train]\n",
      "    y_test = y[test]\n",
      "\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    y_hat = clf.predict(X_test)\n",
      "\n",
      "    p,r,f1_score,support = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
      "\n",
      "    precision.append(p[1])\n",
      "    recall.append(r[1])\n",
      "\n",
      "print 'avg precision:',np.average(precision), '+/-', np.std(precision)\n",
      "print 'avg recall:', np.average(recall), '+/-', np.std(recall)\n",
      "print 'f1 measure', f1_score\n",
      "\n",
      "print \"clf: \", clf\n",
      "print \"cv: \", cv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg precision: 0.650864242749 +/- 0.120665105641\n",
        "avg recall: 0.910531654943 +/- 0.0385943080113\n",
        "f1 measure [ 0.94508916  0.85576208]\n",
        "clf:  LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "cv:  sklearn.cross_validation.StratifiedKFold(labels=['p' 'p' 'p' ..., 'np' 'np' 'np'], n_folds=5, shuffle=False, random_state=None)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('classifierLR.pkl', 'wb') as fid:\n",
      "    pickle.dump(clf, fid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet1 = 'This Veterans Day, join me at #TheConcertForValor, a free event at the #NationalMall in Washington DC https://www.youtube.com/watch?v=U8NtbVL-CKM \u2026'\n",
      "tweet2 = 'Here is our piece on Iraqi and Afghani translators from last night. Buckle up. http://www.youtube.com/watch?v=QplQL5eAxlY&list=UU3XTzVzaHQEd30rQbuvCtTQ&index=1 \u2026'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# concatenate tweets to make a 'timeline' -- \n",
      "# roughly equivalent to rating each tweet separately and then averaging based on this example data\n",
      "timeline = [tweet1, tweet2]\n",
      "sample = makeVector.transform(timeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 75212)\t0.255732542865\n",
        "  (0, 73271)\t0.41030795355\n",
        "  (0, 71484)\t0.250223572535\n",
        "  (0, 71466)\t0.320913238964\n",
        "  (0, 69974)\t0.333089820544\n",
        "  (0, 36885)\t0.280644095449\n",
        "  (0, 32576)\t0.184345290048\n",
        "  (0, 26995)\t0.159297860701\n",
        "  (0, 24309)\t0.324577795282\n",
        "  (0, 19648)\t0.323629931728\n",
        "  (0, 19595)\t0.21466842685\n",
        "  (0, 17175)\t0.308889242197\n",
        "  (1, 75212)\t0.242108603088\n",
        "  (1, 73271)\t0.388449136574\n",
        "  (1, 71484)\t0.236893118597\n",
        "  (1, 51899)\t0.305512078754\n",
        "  (1, 47557)\t0.229725592401\n",
        "  (1, 41184)\t0.295640045047\n",
        "  (1, 34899)\t0.375617319007\n",
        "  (1, 34095)\t0.423393105882\n",
        "  (1, 17175)\t0.292433423213\n",
        "  (1, 13793)\t0.308205173877\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get classifier from pickle\n",
      "with open('classifierLR.pkl', 'rb') as fid:\n",
      "    clf2 = pickle.load(fid)\n",
      "    \n",
      "print clf2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# class prediction\n",
      "prediction = clf2.predict(sample)\n",
      "print prediction\n",
      "\n",
      "# probabilities of belonging to class == SCORE!\n",
      "probs = clf2.predict_proba(sample)\n",
      "print probs\n",
      "print type(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['p' 'p']\n",
        "[[ 0.36713904  0.63286096]\n",
        " [ 0.30096471  0.69903529]]\n",
        "<type 'numpy.ndarray'>\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_political_score(probs):\n",
      "    score = 0\n",
      "    \n",
      "    print len(probs)\n",
      "    \n",
      "    for prob in probs:\n",
      "        score += prob.item(1)\n",
      "            \n",
      "    # higher probabilities in logistic regression indicate p timeline now\n",
      "    # ndarray ordered lexigraphically (np before p)\n",
      "    average_score = score/len(probs)\n",
      "    print average_score\n",
      "    \n",
      "    return average_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "average_political_score(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "0.665948123991\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "0.665948123990544"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def connect_to_API():\n",
      "    \"\"\"\n",
      "    Create instance of tweepy API class with OAuth keys and tokens.\n",
      "    \"\"\"\n",
      "    # initialize tweepy api object with auth, OAuth\n",
      "    TWITTER_API_KEY=os.environ.get('TWITTER_API_KEY')\n",
      "    TWITTER_SECRET_KEY=os.environ.get('TWITTER_SECRET_KEY')\n",
      "    TWITTER_ACCESS_TOKEN=os.environ.get('TWITTER_ACCESS_TOKEN')\n",
      "    TWITTER_SECRET_TOKEN=os.environ.get('TWITTER_SECRET_TOKEN')\n",
      "\n",
      "    auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_SECRET_KEY, secure=True)\n",
      "    auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_SECRET_TOKEN)\n",
      "    api = tweepy.API(auth, cache=None) #removed wait_on_rate_limit=True, wait_on_rate_limit_notify=True\n",
      "    return api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "api = connect_to_API()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_timeline(api, uid, count):\n",
      "    \"\"\"Get n number of tweets by passing in user id and number of statuses.\n",
      "        If user has protected tweets, returns [] rather than break the program.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        feed = tweepy.Cursor(api.user_timeline, id=uid, include_rts=True).items(count)\n",
      "        # logging.info(\"\\n\\n\\n\", \"Get timeline: \", feed, \"\\n\\n\\n\")\n",
      "        print \"get request timeline\"\n",
      "        return feed\n",
      "\n",
      "    except tweepy.TweepError as e:\n",
      "        print e.message[0][\"error\"]\n",
      "        return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maddow = get_timeline(api, \"maddow\", 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get request timeline\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kimkardashian = get_timeline(api, \"KimKardashian\", 20)\n",
      "scalzi = get_timeline(api, \"scalzi\", 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get request timeline\n",
        "get request timeline\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeline = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tweet in kimkardashian:\n",
      "    timeline.append(tweet.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = makeVector.transform(timeline)\n",
      "print sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 55739)\t0.362752214141\n",
        "  (0, 47216)\t0.227001545868\n",
        "  (0, 44696)\t0.424137369653\n",
        "  (0, 22608)\t0.443923811201\n",
        "  (0, 16919)\t0.494313326315\n",
        "  (0, 2933)\t0.44223817819\n",
        "  (1, 59224)\t0.36295401824\n",
        "  (1, 44174)\t0.332274797989\n",
        "  (1, 43840)\t0.330431069591\n",
        "  (1, 39593)\t0.443664649129\n",
        "  (1, 29429)\t0.431732442714\n",
        "  (1, 28813)\t0.348160190395\n",
        "  (1, 11101)\t0.379771518624\n",
        "  (2, 63275)\t0.399940339829\n",
        "  (2, 47216)\t0.317635142759\n",
        "  (2, 23844)\t0.577233585934\n",
        "  (2, 15138)\t0.63714757155\n",
        "  (3, 74032)\t0.448625243652\n",
        "  (3, 67494)\t0.424505819253\n",
        "  (3, 65125)\t0.261688137199\n",
        "  (3, 63404)\t0.275713833318\n",
        "  (3, 58026)\t0.388875996474\n",
        "  (3, 41793)\t0.161074456575\n",
        "  (3, 38679)\t0.478499867242\n",
        "  (3, 8279)\t0.260575818141\n",
        "  :\t:\n",
        "  (15, 47216)\t0.271471495978\n",
        "  (15, 41749)\t0.535123665495\n",
        "  (15, 25289)\t0.361026245987\n",
        "  (15, 12193)\t0.344259251555\n",
        "  (16, 70777)\t1.0\n",
        "  (17, 65114)\t0.2605277266\n",
        "  (17, 45297)\t0.431219963358\n",
        "  (17, 40118)\t0.352773246084\n",
        "  (17, 26908)\t0.372106581623\n",
        "  (17, 25246)\t0.431219963358\n",
        "  (17, 22049)\t0.378841139513\n",
        "  (17, 14621)\t0.307224284284\n",
        "  (17, 8279)\t0.243730074046\n",
        "  (18, 50807)\t0.370990498317\n",
        "  (18, 47575)\t0.405244372754\n",
        "  (18, 43768)\t0.514136200361\n",
        "  (18, 41627)\t0.276434568376\n",
        "  (18, 28821)\t0.409879222374\n",
        "  (18, 7925)\t0.43518957761\n",
        "  (19, 35825)\t0.451260596998\n",
        "  (19, 35086)\t0.422103604398\n",
        "  (19, 25906)\t0.400511470667\n",
        "  (19, 17985)\t0.341503369106\n",
        "  (19, 17417)\t0.451260596998\n",
        "  (19, 1506)\t0.370839999329\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# class prediction\n",
      "prediction = clf2.predict(sample)\n",
      "print prediction\n",
      "\n",
      "# probabilities of belonging to class == SCORE!\n",
      "probs = clf2.predict_proba(sample)\n",
      "print probs\n",
      "print zip(prediction, timeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['p' 'p' 'np' 'np' 'p' 'p' 'p' 'p' 'np' 'np' 'np' 'p' 'p' 'p' 'np' 'np' 'p'\n",
        " 'np' 'np' 'p']\n",
        "[[ 0.40450341  0.59549659]\n",
        " [ 0.28846351  0.71153649]\n",
        " [ 0.88171189  0.11828811]\n",
        " [ 0.63641193  0.36358807]\n",
        " [ 0.03540848  0.96459152]\n",
        " [ 0.32704699  0.67295301]\n",
        " [ 0.34207746  0.65792254]\n",
        " [ 0.39505895  0.60494105]\n",
        " [ 0.6007487   0.3992513 ]\n",
        " [ 0.5574228   0.4425772 ]\n",
        " [ 0.66971109  0.33028891]\n",
        " [ 0.42400712  0.57599288]\n",
        " [ 0.49366883  0.50633117]\n",
        " [ 0.4649722   0.5350278 ]\n",
        " [ 0.9632393   0.0367607 ]\n",
        " [ 0.50319718  0.49680282]\n",
        " [ 0.41532909  0.58467091]\n",
        " [ 0.52825712  0.47174288]\n",
        " [ 0.55460876  0.44539124]\n",
        " [ 0.39624062  0.60375938]]\n",
        "[('p', 'East coast, only 45 minutes for an all new #KKTH. Are you ready?'), ('p', u'So glad I screen grabbed this Bday message from Kylie. This means so much to me \\u2764\\ufe0f http://t.co/tXNMVrG1Pa'), ('np', '#KKTH Sunday is here! Catch an all new episode at 9/8c only on E!'), ('np', 'I found an amazing kimye tumblr! http://t.co/2SZVzLvWe8  thanks for the love and support to whoever runs this! xoxoxo'), ('p', 'LOL http://t.co/XqcQmuwJSP'), ('p', 'Did you guys enjoy Thanksgiving???? http://t.co/EDl89pgiCm'), ('p', 'So JetLagged! I need to fall back asleep. My little lady wakes up in 3 hours! Ughhh'), ('p', 'Who shopped on Black Friday??? #DealsAllWeekend #KimKardashianGame http://t.co/eeZkqR4pxg'), ('np', 'Just posted some EBay auctions #Balmain #SaintLaurent #KardashianKollection &amp; more! http://t.co/yqGnYXpjwt\\n @auctioncause &amp; @ebaygivingworks'), ('np', u'North &amp; Georgia \\U0001f436 http://t.co/CTxsJEMNal'), ('np', u\"I'm so thankful for my best friend N+K=\\u2764\\ufe0f http://t.co/UuFE3DHo7u\"), ('p', \"Thank you for starting a new tradition Khlo! Thanksgiving at Koko's\"), ('p', \"Happy Thanksgiving! I'm so thankful to have spent the day with my whole family over at Khloes house today! Khloe cooked so much yummy food!\"), ('p', \"My brother @robkardashian's @arthurgeorge loungewear line is now in select Macy's stores! Go to http://t.co/kUS2qTDWIc for store list!\"), ('np', 'Happy Birthday @MIKESNEDEGAR !!!!!!! love you!!!!!!'), ('np', u'I\\u2019m obsessed with our new Black Bronzer\\u2026what\\u2019s your favorite #KardashianGlow lotion? http://t.co/DHHuHGPYY0'), ('p', u'#VroomVroom #DubaiDesert \\U0001f6a9\\U0001f6a7\\U0001f6a6\\U0001f6a9 http://t.co/2mv71Ezmtv'), ('np', 'Thank you to everyone that came out to my Fleur Fatale fragrance launch at Parfum Monde! Dubai has been amazing! http://t.co/YjB9SIjkGO'), ('np', 'Last nights look- Balmain top, Alexander McQueen pants Glam @joycebonelli @thescottycunha http://t.co/W2QreFq2pB'), ('p', \"Third and final cover for @ELLEUK's January 2015 Confidence Issue! http://t.co/JGxEyHOUYE http://t.co/xFkuRoXjKI\")]\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "average_political_score(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20\n",
        "0.505895727656\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "0.5058957276559882"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}