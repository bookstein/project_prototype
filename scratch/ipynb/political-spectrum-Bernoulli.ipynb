{
 "metadata": {
  "name": "",
  "signature": "sha256:0d817605273362a1ad30ea03d397a456dd299ba19d5d40050f1628c12c663b81"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import simplejson as json\n",
      "import os\n",
      "import string\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "import tweepy\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "\n",
      "import modelNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEXT = []\n",
      "LABELS = []\n",
      "\n",
      "data = modelNB.Status.get_all_statuses()\n",
      "for status in data:\n",
      "    TEXT.append(status.text.lower())\n",
      "    #label 'p' for political\n",
      "    if status.label == \"p\":\n",
      "        LABELS.append(\"p\")\n",
      "    else:\n",
      "        LABELS.append(\"np\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"TEXT LEN:\", len(TEXT)\n",
      "print \"LABELS LEN:\", len(LABELS)\n",
      "print TEXT[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TEXT LEN: 60291\n",
        "LABELS LEN: 60291\n",
        "@npr--reconsider gutting @nprscience: we need more climate coverage! (i  pledge @ kqed-fm.) http://t.co/vxpwc8wqlr via @credomobile #p2\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ENGLISH_STOP_WORDS = [\n",
      "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
      "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
      "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
      "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
      "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
      "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
      "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
      "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
      "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
      "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
      "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
      "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\",\n",
      "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
      "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
      "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
      "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
      "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
      "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
      "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
      "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
      "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
      "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
      "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
      "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
      "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
      "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
      "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
      "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
      "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
      "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
      "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
      "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
      "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
      "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
      "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
      "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
      "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
      "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
      "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
      "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
      "    \"yourselves\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stops = ['http', 'rt']\n",
      "stops.extend(ENGLISH_STOP_WORDS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "makeVector = TfidfVectorizer(analyzer=\"word\", stop_words=stops)\n",
      "print makeVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=['http', 'rt', 'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', '...ill', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves'],\n",
        "        strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create vector from raw documents (X)\n",
      "X = makeVector.fit_transform(TEXT)\n",
      "print X.shape\n",
      "# print X\n",
      "\n",
      "# create numpy array of labels\n",
      "# numpy arrays = n-dimensional array with collection of items all the same type. Homogenous.\n",
      "y = np.array(LABELS)\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(60291, 87877)\n",
        "(60291,)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fraction_np(text_list, label_list):\n",
      "    \"\"\"\n",
      "    Get fraction of training data that is associated with \"np\" (nonpolitical)\n",
      "    label.\n",
      "    \"\"\"\n",
      "    # get number of nonpolitical\n",
      "    np_list = [label for label in label_list if label == 'np']\n",
      "    \n",
      "#     print len(text_list)\n",
      "#     print len(np_list)\n",
      "    \n",
      "    return float(len(np_list))/float(len(text_list))\n",
      "\n",
      "print get_fraction_np(TEXT, LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.585228309366\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = BernoulliNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X, y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Kfolds = 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = cross_validation.StratifiedKFold(y, Kfolds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision = []\n",
      "recall = []\n",
      "\n",
      "for train, test in cv:\n",
      "    X_train = X[train]\n",
      "    X_test = X[test]\n",
      "    y_train = y[train]\n",
      "    y_test = y[test]\n",
      "\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    y_hat = clf.predict(X_test)\n",
      "\n",
      "    p,r,f1_score,support = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
      "\n",
      "    precision.append(p[1])\n",
      "    recall.append(r[1])\n",
      "\n",
      "print 'avg precision:',np.average(precision), '+/-', np.std(precision)\n",
      "print 'avg recall:', np.average(recall), '+/-', np.std(recall)\n",
      "print 'f1 measure', f1_score\n",
      "\n",
      "print \"clf: \", clf\n",
      "print \"cv: \", cv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg precision: 0.876287174661 +/- 0.0433558413039\n",
        "avg recall: 0.883154220815 +/- 0.0527393070166\n",
        "f1 measure [ 0.94976009  0.92838463]\n",
        "clf:  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "cv:  sklearn.cross_validation.StratifiedKFold(labels=['p' 'p' 'p' ..., 'p' 'p' 'p'], n_folds=5, shuffle=False, random_state=None)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('classifierNB.pkl', 'wb') as fid:\n",
      "    pickle.dump(clf, fid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet1 = 'This Veterans Day, join me at #TheConcertForValor, a free event at the #NationalMall in Washington DC https://www.youtube.com/watch?v=U8NtbVL-CKM \u2026'\n",
      "tweet2 = 'Here is our piece on Iraqi and Afghani translators from last night. Buckle up. http://www.youtube.com/watch?v=QplQL5eAxlY&list=UU3XTzVzaHQEd30rQbuvCtTQ&index=1 \u2026'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# concatenate tweets to make a 'timeline' -- \n",
      "# roughly equivalent to rating each tweet separately and then averaging based on this example data\n",
      "timeline = [tweet1, tweet2]\n",
      "sample = makeVector.transform(timeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 86082)\t0.260768493071\n",
        "  (0, 83884)\t0.409864219121\n",
        "  (0, 81831)\t0.253641773753\n",
        "  (0, 81809)\t0.313798315677\n",
        "  (0, 80119)\t0.323722928785\n",
        "  (0, 42219)\t0.27150157644\n",
        "  (0, 37300)\t0.187901262165\n",
        "  (0, 30919)\t0.167011335914\n",
        "  (0, 27853)\t0.334061373706\n",
        "  (0, 22474)\t0.318459134838\n",
        "  (0, 22408)\t0.219124773653\n",
        "  (0, 19647)\t0.313798315677\n",
        "  (1, 86082)\t0.247584439993\n",
        "  (1, 83884)\t0.38914211594\n",
        "  (1, 81831)\t0.240818036619\n",
        "  (1, 59520)\t0.30604474877\n",
        "  (1, 54459)\t0.235474643621\n",
        "  (1, 47166)\t0.293493857349\n",
        "  (1, 39920)\t0.383977375005\n",
        "  (1, 39032)\t0.395104371787\n",
        "  (1, 19647)\t0.297933156505\n",
        "  (1, 15829)\t0.318930143932\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get classifier from pickle\n",
      "with open('classifierNB.pkl', 'rb') as fid:\n",
      "    clf2 = pickle.load(fid)\n",
      "    \n",
      "print clf2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# class prediction\n",
      "prediction = clf2.predict(sample)\n",
      "print prediction\n",
      "\n",
      "# probabilities of belonging to class == SCORE!\n",
      "probs = clf2.predict_proba(sample)\n",
      "print probs\n",
      "print type(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['p' 'np']\n",
        "[[ 0.10850187  0.89149813]\n",
        " [ 0.59982854  0.40017146]]\n",
        "<type 'numpy.ndarray'>\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_political_score(probs):\n",
      "    score = 0\n",
      "    \n",
      "    print len(probs)\n",
      "    \n",
      "    for prob in probs:\n",
      "        score += prob.item(1)\n",
      "            \n",
      "    # higher probabilities in logistic regression indicate p timeline now\n",
      "    # ndarray ordered lexigraphically (np before p)\n",
      "    average_score = score/len(probs)\n",
      "    print average_score\n",
      "    \n",
      "    return average_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "average_political_score(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "0.645834796201\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "0.6458347962012603"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def connect_to_API():\n",
      "    \"\"\"\n",
      "    Create instance of tweepy API class with OAuth keys and tokens.\n",
      "    \"\"\"\n",
      "    # initialize tweepy api object with auth, OAuth\n",
      "    TWITTER_API_KEY=os.environ.get('TWITTER_API_KEY')\n",
      "    TWITTER_SECRET_KEY=os.environ.get('TWITTER_SECRET_KEY')\n",
      "    TWITTER_ACCESS_TOKEN=os.environ.get('TWITTER_ACCESS_TOKEN')\n",
      "    TWITTER_SECRET_TOKEN=os.environ.get('TWITTER_SECRET_TOKEN')\n",
      "\n",
      "    auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_SECRET_KEY, secure=True)\n",
      "    auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_SECRET_TOKEN)\n",
      "    api = tweepy.API(auth, cache=None) #removed wait_on_rate_limit=True, wait_on_rate_limit_notify=True\n",
      "    return api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "api = connect_to_API()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_timeline(api, uid, count):\n",
      "    \"\"\"Get n number of tweets by passing in user id and number of statuses.\n",
      "        If user has protected tweets, returns [] rather than break the program.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        feed = tweepy.Cursor(api.user_timeline, id=uid, include_rts=True).items(count)\n",
      "        # logging.info(\"\\n\\n\\n\", \"Get timeline: \", feed, \"\\n\\n\\n\")\n",
      "        print \"get request timeline\"\n",
      "        return feed\n",
      "\n",
      "    except tweepy.TweepError as e:\n",
      "        print e.message[0][\"error\"]\n",
      "        return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maddow = get_timeline(api, \"maddow\", 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get request timeline\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kimkardashian = get_timeline(api, \"KimKardashian\", 20)\n",
      "scalzi = get_timeline(api, \"scalzi\", 20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get request timeline\n",
        "get request timeline\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeline = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tweet in maddow:\n",
      "    timeline.append(tweet.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = makeVector.transform(timeline)\n",
      "print sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 63923)\t0.364285762612\n",
        "  (0, 54063)\t0.230272299351\n",
        "  (0, 51175)\t0.417140543631\n",
        "  (0, 25897)\t0.452347113938\n",
        "  (0, 19363)\t0.487602514732\n",
        "  (0, 3412)\t0.444848507145\n",
        "  (1, 67909)\t0.354553928277\n",
        "  (1, 50564)\t0.332071721873\n",
        "  (1, 50193)\t0.322658150686\n",
        "  (1, 45351)\t0.440873478729\n",
        "  (1, 33700)\t0.440873478729\n",
        "  (1, 32990)\t0.346341997867\n",
        "  (1, 12776)\t0.388870123936\n",
        "  (2, 72495)\t0.404998354488\n",
        "  (2, 54063)\t0.317286626166\n",
        "  (2, 27319)\t0.575921215381\n",
        "  (2, 17346)\t0.635311170524\n",
        "  (3, 84755)\t0.452181611484\n",
        "  (3, 77253)\t0.422670413594\n",
        "  (3, 74599)\t0.256007150394\n",
        "  (3, 72640)\t0.266691862784\n",
        "  (3, 66544)\t0.388144525359\n",
        "  (3, 47854)\t0.166567517764\n",
        "  (3, 44283)\t0.481692809374\n",
        "  (3, 9529)\t0.264174994725\n",
        "  :\t:\n",
        "  (36, 65224)\t0.443655514181\n",
        "  (36, 52480)\t0.334099188397\n",
        "  (36, 47198)\t0.287848557603\n",
        "  (36, 42827)\t0.222476340029\n",
        "  (36, 29590)\t0.35299079974\n",
        "  (36, 27082)\t0.508246359984\n",
        "  (37, 65320)\t0.260585017084\n",
        "  (37, 65224)\t0.437609632298\n",
        "  (37, 52480)\t0.329546277038\n",
        "  (37, 36827)\t0.400341297616\n",
        "  (37, 27082)\t0.501320271246\n",
        "  (37, 15926)\t0.469464951772\n",
        "  (38, 65320)\t0.281393840595\n",
        "  (38, 65224)\t0.472554625326\n",
        "  (38, 52480)\t0.355861950879\n",
        "  (38, 27082)\t0.541352830154\n",
        "  (38, 18785)\t0.52707591271\n",
        "  (39, 71928)\t0.424741240276\n",
        "  (39, 65320)\t0.250631982213\n",
        "  (39, 65224)\t0.420895148945\n",
        "  (39, 52480)\t0.316959269451\n",
        "  (39, 47198)\t0.27308138331\n",
        "  (39, 40068)\t0.280572032733\n",
        "  (39, 27082)\t0.482172362448\n",
        "  (39, 18766)\t0.305578613181\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# class prediction\n",
      "prediction = clf2.predict(sample)\n",
      "print prediction\n",
      "\n",
      "# probabilities of belonging to class == SCORE!\n",
      "probs = clf2.predict_proba(sample)\n",
      "print probs\n",
      "print zip(prediction, timeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['np' 'p' 'np' 'np' 'np' 'np' 'p' 'np' 'np' 'np' 'np' 'np' 'np' 'np' 'np'\n",
        " 'np' 'np' 'np' 'np' 'p' 'p' 'np' 'p' 'p' 'np' 'p' 'p' 'p' 'p' 'p' 'np'\n",
        " 'np' 'p' 'p' 'np' 'p' 'p' 'p' 'p' 'p']\n",
        "[[  8.15710615e-01   1.84289385e-01]\n",
        " [  3.92337899e-01   6.07662101e-01]\n",
        " [  9.45801329e-01   5.41986707e-02]\n",
        " [  9.57988503e-01   4.20114973e-02]\n",
        " [  8.39584317e-01   1.60415683e-01]\n",
        " [  5.52523081e-01   4.47476919e-01]\n",
        " [  4.59335568e-01   5.40664432e-01]\n",
        " [  6.41116087e-01   3.58883913e-01]\n",
        " [  9.98826242e-01   1.17375838e-03]\n",
        " [  8.77226781e-01   1.22773219e-01]\n",
        " [  9.72847117e-01   2.71528829e-02]\n",
        " [  7.12268235e-01   2.87731765e-01]\n",
        " [  9.87207005e-01   1.27929953e-02]\n",
        " [  8.35012348e-01   1.64987652e-01]\n",
        " [  9.96938350e-01   3.06165019e-03]\n",
        " [  9.97583602e-01   2.41639800e-03]\n",
        " [  7.41492049e-01   2.58507951e-01]\n",
        " [  9.94722431e-01   5.27756867e-03]\n",
        " [  9.90883193e-01   9.11680749e-03]\n",
        " [  4.00569822e-01   5.99430178e-01]\n",
        " [  2.15329121e-02   9.78467088e-01]\n",
        " [  9.53264089e-01   4.67359114e-02]\n",
        " [  2.79952684e-01   7.20047316e-01]\n",
        " [  8.65067380e-02   9.13493262e-01]\n",
        " [  7.73463295e-01   2.26536705e-01]\n",
        " [  3.83423613e-06   9.99996166e-01]\n",
        " [  8.75429711e-08   9.99999912e-01]\n",
        " [  4.55110190e-02   9.54488981e-01]\n",
        " [  1.10490093e-04   9.99889510e-01]\n",
        " [  2.31655029e-04   9.99768345e-01]\n",
        " [  9.08613227e-01   9.13867730e-02]\n",
        " [  8.72281428e-01   1.27718572e-01]\n",
        " [  1.89900413e-02   9.81009959e-01]\n",
        " [  3.34799602e-02   9.66520040e-01]\n",
        " [  9.86477731e-01   1.35222689e-02]\n",
        " [  3.32788403e-03   9.96672116e-01]\n",
        " [  1.69341526e-02   9.83065847e-01]\n",
        " [  1.50673850e-01   8.49326150e-01]\n",
        " [  1.69163800e-02   9.83083620e-01]\n",
        " [  9.50636581e-03   9.90493634e-01]]\n",
        "[('np', 'East coast, only 45 minutes for an all new #KKTH. Are you ready?'), ('p', u'So glad I screen grabbed this Bday message from Kylie. This means so much to me \\u2764\\ufe0f http://t.co/tXNMVrG1Pa'), ('np', '#KKTH Sunday is here! Catch an all new episode at 9/8c only on E!'), ('np', 'I found an amazing kimye tumblr! http://t.co/2SZVzLvWe8  thanks for the love and support to whoever runs this! xoxoxo'), ('np', 'LOL http://t.co/XqcQmuwJSP'), ('np', 'Did you guys enjoy Thanksgiving???? http://t.co/EDl89pgiCm'), ('p', 'So JetLagged! I need to fall back asleep. My little lady wakes up in 3 hours! Ughhh'), ('np', 'Who shopped on Black Friday??? #DealsAllWeekend #KimKardashianGame http://t.co/eeZkqR4pxg'), ('np', 'Just posted some EBay auctions #Balmain #SaintLaurent #KardashianKollection &amp; more! http://t.co/yqGnYXpjwt\\n @auctioncause &amp; @ebaygivingworks'), ('np', u'North &amp; Georgia \\U0001f436 http://t.co/CTxsJEMNal'), ('np', u\"I'm so thankful for my best friend N+K=\\u2764\\ufe0f http://t.co/UuFE3DHo7u\"), ('np', \"Thank you for starting a new tradition Khlo! Thanksgiving at Koko's\"), ('np', \"Happy Thanksgiving! I'm so thankful to have spent the day with my whole family over at Khloes house today! Khloe cooked so much yummy food!\"), ('np', \"My brother @robkardashian's @arthurgeorge loungewear line is now in select Macy's stores! Go to http://t.co/kUS2qTDWIc for store list!\"), ('np', 'Happy Birthday @MIKESNEDEGAR !!!!!!! love you!!!!!!'), ('np', u'I\\u2019m obsessed with our new Black Bronzer\\u2026what\\u2019s your favorite #KardashianGlow lotion? http://t.co/DHHuHGPYY0'), ('np', u'#VroomVroom #DubaiDesert \\U0001f6a9\\U0001f6a7\\U0001f6a6\\U0001f6a9 http://t.co/2mv71Ezmtv'), ('np', 'Thank you to everyone that came out to my Fleur Fatale fragrance launch at Parfum Monde! Dubai has been amazing! http://t.co/YjB9SIjkGO'), ('np', 'Last nights look- Balmain top, Alexander McQueen pants Glam @joycebonelli @thescottycunha http://t.co/W2QreFq2pB'), ('p', \"Third and final cover for @ELLEUK's January 2015 Confidence Issue! http://t.co/JGxEyHOUYE http://t.co/xFkuRoXjKI\"), ('p', 'TIL that recreational flavored oxygen is a thing. Thanks, TSA! http://t.co/4SdCChXIfZ'), ('np', 'Folks here http://t.co/BsUAt0D6xX have set up a wishlist where you can buy books for the @FergusonLibrary: http://t.co/YIrXPFGZVB'), ('p', u'RT @ScottyBonner: A video tour of the #Ferguson Library! http://t.co/xgD7dUSmmw Watch on computer so you can get the annotations. They help\\u2026'), ('p', u'RT @fergusonlibrary: We are open 9-4.  Wifi, water, rest, knowledge. We are here for you. If neighbors have kids, let them know teachers ar\\u2026'), ('np', u\"RT @fergusonlibrary: WE ARE OPEN! Teachers and volunteers are here 9am-3pm to help kids who can't go to school today. Library open 9-4, pre\\u2026\"), ('p', \"I'll be anchoring at 9pm ET on MSNBC, when we expect to hear the grand jury's decision in the Michael Brown case.\"), ('p', 'RT @msnbc: .@ACLU making sure #Ferguson protesters know their rights: http://t.co/IE7fLMgqSB http://t.co/7iGuQnO1yZ'), ('p', u'RT @zackbeauchamp: That sound you hear is thousands of journalists double-checking how to spell Mich\\xe8le Flournoy.'), ('p', u'Chilling stuff from @dcbigjohn -- Terrorists Shot This Journalist Twice And He Can\\u2019t Get U.S. Asylum http://t.co/LlrJ3p8d16'), ('p', 'Earwax?? This NV GOP story was pretty twisty already, but this is a turn I did not expect: http://t.co/bEgQefoy70'), ('np', u\"RT @AymanM: It's official! Happy to announce that I've relocated to New York...Still a foreign correspondent for\\u2026 http://t.co/pZshtSiKp9\"), ('np', 'Buffalo News headline: \"Second snow punch comes Thursday, with 2 more feet\" http://t.co/CXjh8WRjr6'), ('p', u'RT @JimCantore: People still in cars RT @JeremyGlobalTV: Longest interstate in USA at standstill. Snowmobiles patrolling i90 #Buffalo http:\\u2026'), ('p', u\"RT @feliciasonmez: Air quality in Beijing currently 361 (hazardous) per US emb. View out window pure white haze. Says colleague: 'APEC is o\\u2026\"), ('np', 'Richard Engel live from Urfa Turkey tonight was just incredible.'), ('p', 'Keir Simmons and Richard Engel shouting out local crews and journalists who can shoot footage in the middle of the ISIS fight...'), ('p', '\"through this little peephole... the proximity in which these two sides are fighting each other\"...Richard Engel on MSNBC just now'), ('p', '\"the bullet of honor...\" Richard Engel on MSNBC right now.'), ('p', '\"there are still civilians here...\" Richard Engel on MSNBC right now.'), ('p', '\"The little city that stood up to ISIS\"... Richard Engel on MSNBC right now.')]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "average_political_score(probs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40\n",
        "0.467806190051\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "0.4678061900505335"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}