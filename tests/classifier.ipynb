{
 "metadata": {
  "name": "",
  "signature": "sha256:e4eded831cffaec9095669ed9421a25f9e4336dd6da7183e8bd4c950b56e1e0d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import simplejson as json\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HASHTAGS = []\n",
      "LABELS = []\n",
      "LIBERAL_TWEETS_PATH = \"../json/maddow/self.json\"\n",
      "CONSERVATIVE_TWEETS_PATH = \"../json/rushlimbaugh/self.json\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_json_data(filename):\n",
      "    \"\"\"\n",
      "    Input filename containing array of JSON-format statuses.\n",
      "    Output is list of dictionaries representing Twitter\n",
      "    timeline from one user.\n",
      "\n",
      "    #TODO: get data from database, not json, for training data\n",
      "    This affects extract_hashtags function as well.\n",
      "\n",
      "    \"\"\"\n",
      "    with open(filename) as f:\n",
      "        # decodes all file data from json\n",
      "        statuses_data = json.load(f)\n",
      "        return statuses_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lib_tweets = get_json_data(LIBERAL_TWEETS_PATH)\n",
      "cons_tweets = get_json_data(CONSERVATIVE_TWEETS_PATH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_hashtags(statuses, hashtag_list, label_list, label):\n",
      "    \"\"\"\n",
      "    Extract hashtags from a given twitter user's timeline and\n",
      "    append them to an existing list.\n",
      "    Add corresponding label to a list of labels.\n",
      "    Parameters:\n",
      "    -----------\n",
      "    Hashtag_list is the list of hashtags to which new hashtags will be added.\n",
      "    Statuses refers to the new twitter user timeline, a python object\n",
      "    containing status objects.\n",
      "    Label_list is the corresponding list of labels for hashtags added in batches\n",
      "    to hashtag_list.\n",
      "    Label is the label that is appended to label_list (either \"lib\" or \"cons\")\n",
      "    Output:\n",
      "    -------\n",
      "    Side-effect, modifying hashtag_list and label_list. Does not return a value.\n",
      "    \"\"\"\n",
      "    for status in statuses:\n",
      "        new_hashtags = status[\"entities\"][\"hashtags\"]\n",
      "        # will skip over empty lists - no obj inside\n",
      "        for hashtag_obj in new_hashtags:\n",
      "            hashtag_list.append(hashtag_obj[\"text\"])\n",
      "            label_list.append(label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(10):\n",
      "    extract_hashtags(lib_tweets, HASHTAGS, LABELS, \"lib\")\n",
      "    extract_hashtags(cons_tweets, HASHTAGS, LABELS, \"cons\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print HASHTAGS\n",
      "print LABELS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf', 'happyhalloween', 'COpolitics', 'CookerPot', 'Maddow', 'KSSen', 'KSSen', 'KSSen', 'watchthisspace', 'IranOnISIS', 'SenatorRubio', 'ImmigrationReform', 'SenatorRubio', 'ImmigrationReform', 'RushCureAThon', 'RushBabesforAmerica', 'NotNOW', 'rushbabes', 'RushBabesforAmerica', 'NationalOrganizationforRushBabes', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'RushLLSRadiothon', 'demastroturf']\n",
        "['lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'lib', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons']\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fraction_cons(hashtag_list, label_list):\n",
      "    \"\"\"\n",
      "    Get fraction of training data that is associated with \"cons\" (conservative)\n",
      "    label.\n",
      "    \"\"\"\n",
      "    total_length = len(hashtag_list)\n",
      "    print \"total length\", total_length\n",
      "    cons_list = [label for label in label_list if label == 'cons']\n",
      "    print cons_list\n",
      "    cons_fraction = len([label for label in label_list if label == 'cons'])\n",
      "    print \"fraction of data that is conservative: \", cons_fraction, \" out of \", total_length\n",
      "    return cons_fraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_fraction_cons(HASHTAGS, LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total length 260\n",
        "['cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons', 'cons']\n",
        "fraction of data that is conservative:  170  out of  260\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "170"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def vectorize(hashtag_list, label_list):\n",
      "    \"\"\"\n",
      "    \"Vectorize\" hashtag list and labels list into a matrix of token counts.\n",
      "\n",
      "    Parameters:\n",
      "    -----------\n",
      "    List of all hashtags in dataset as strings, list of all associated labels\n",
      "    as strings.\n",
      "\n",
      "    Output:\n",
      "    -------\n",
      "    Matrix of token counts (hashtags, by occurrence)\n",
      "\n",
      "    Note: CountVectorizer can also look at ngrams - useful for examining entire\n",
      "    tweet text instead of hashtags.\n",
      "    \"\"\"\n",
      "    makeVector = CountVectorizer()\n",
      "\n",
      "    X = makeVector.fit_transform(hashtag_list)\n",
      "    y = np.array(label_list)\n",
      "\n",
      "    return X, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = vectorize(HASHTAGS, LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def init_and_train_classifier(X, y, Kfolds):\n",
      "    \"\"\"\n",
      "    Instantiates and trains a classifier.\n",
      "\n",
      "    Parameters:\n",
      "    ----------\n",
      "    List of labels (as numpy array)\n",
      "    Number of stratified folds into which to divide all labelled data.\n",
      "\n",
      "    Output:\n",
      "    -------\n",
      "    Trained classifier\n",
      "    \"\"\"\n",
      "\n",
      "    clf = BernoulliNB()\n",
      "\n",
      "    cv = cross_validation.StratifiedKFold(y, Kfolds)\n",
      "\n",
      "    precision = []\n",
      "    recall = []\n",
      "\n",
      "    for train, test in cv:\n",
      "        X_train = X[train]\n",
      "        X_test = X[test]\n",
      "        y_train = y[train]\n",
      "        y_test = y[test]\n",
      "\n",
      "        clf.fit(X_train, y_train)\n",
      "\n",
      "        y_hat = clf.predict(X_test)\n",
      "\n",
      "    # TODO: double-check that I understand r and p (why are they appended to array?)!\n",
      "        p,r,f1_score,support = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
      "#         precision.append(p[1])\n",
      "#         recall.append(r[1])\n",
      "        \n",
      "        precision.append(p[1])\n",
      "        recall.append(r[1])\n",
      "    \n",
      "    print 'precision:',np.average(precision), '+/-', np.std(precision)\n",
      "    print 'recall:', np.average(recall), '+/-', np.std(recall)\n",
      "\n",
      "\n",
      "    print \"clf: \", clf\n",
      "    print \"cv: \", cv\n",
      "    \n",
      "\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "init_and_train_classifier(X, y, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "precision: 1.0 +/- 0.0\n",
        "recall: 1.0 +/- 0.0\n",
        "clf:  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "cv:  sklearn.cross_validation.StratifiedKFold(labels=['lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'lib' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'lib' 'lib' 'lib' 'lib' 'lib'\n",
        " 'lib' 'lib' 'lib' 'lib' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'\n",
        " 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons' 'cons'], n_folds=3, shuffle=False, random_state=None)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}