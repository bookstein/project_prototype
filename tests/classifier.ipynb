{
 "metadata": {
  "name": "",
  "signature": "sha256:c4996ac7062f1757a08ba23f8bb705fceb086d52606f1e6250fbb3cbe7120ba9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import simplejson as json\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn import cross_validation\n",
      "from sklearn import metrics\n",
      "\n",
      "import model\n",
      "\n",
      "import os\n",
      "\n",
      "import tweepy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEXT = []\n",
      "LABELS = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get all records (labeled tweets from #tcot feed and #p2 feed) from database\n",
      "data = model.Status.get_all_statuses()\n",
      "for status in data:\n",
      "    TEXT.append(status.text)\n",
      "    LABELS.append(status.label)\n",
      "\n",
      "print len(TEXT)\n",
      "print len(LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6000\n",
        "6000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"TEXT:\", TEXT[1], \"LABEL:\", LABELS[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TEXT: RT @jjauthor: Apparently with \"legalization first with no secure border\"-how many terrorists do Democrats want to let into America? #tcot #\u2026 LABEL: cons\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fraction_cons(text_list, label_list):\n",
      "    \"\"\"\n",
      "    Get fraction of training data that is associated with \"cons\" (conservative)\n",
      "    label.\n",
      "    \"\"\"\n",
      "    total_length = len(text_list)\n",
      "    # print \"total length\", total_length\n",
      "    cons_list = [label for label in label_list if label == 'cons']\n",
      "    # print cons_list\n",
      "    cons_fraction = len([label for label in label_list if label == 'cons'])\n",
      "    # print \"fraction of data that is conservative: \", cons_fraction, \" out of \", total_length\n",
      "    return cons_fraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_fraction_cons(TEXT, LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "3000"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# makes vector\n",
      "makeVector = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\")\n",
      "print makeVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create vector from raw documents (X)\n",
      "X = makeVector.fit_transform(TEXT)\n",
      "# create numpy array\n",
      "y = np.array(LABELS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def init_and_train_classifier(X, y, Kfolds):\n",
      "    \"\"\"\n",
      "    Instantiates and trains a classifier.\n",
      "\n",
      "    Parameters:\n",
      "    ----------\n",
      "    Matrix of documents and features\n",
      "    List of labels (as numpy array)\n",
      "    Number of stratified folds into which to divide all labelled data.\n",
      "\n",
      "    Output:\n",
      "    -------\n",
      "    Trained classifier\n",
      "    \"\"\"\n",
      "\n",
      "    clf = MultinomialNB()\n",
      "\n",
      "    cv = cross_validation.StratifiedKFold(y, Kfolds)\n",
      "\n",
      "    precision = []\n",
      "    recall = []\n",
      "\n",
      "    for train, test in cv:\n",
      "        X_train = X[train]\n",
      "        X_test = X[test]\n",
      "        y_train = y[train]\n",
      "        y_test = y[test]\n",
      "\n",
      "        clf.fit(X_train, y_train)\n",
      "\n",
      "        y_hat = clf.predict(X_test)\n",
      "\n",
      "        p,r,f1_score,support = metrics.precision_recall_fscore_support(y_test, y_hat)\n",
      "\n",
      "        precision.append(p[1])\n",
      "        recall.append(r[1])\n",
      "\n",
      "    print 'avg precision:',np.average(precision), '+/-', np.std(precision)\n",
      "    print 'avg recall:', np.average(recall), '+/-', np.std(recall)\n",
      "    print 'f1 measure', f1_score\n",
      "\n",
      "    print \"clf: \", clf\n",
      "    print \"cv: \", cv\n",
      "\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = init_and_train_classifier(X, y, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "avg precision: 0.968215455883 +/- 0.00958821987777\n",
        "avg recall: 0.935333333333 +/- 0.0193620476419\n",
        "f1 measure [ 0.94736842  0.94420601]\n",
        "clf:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
        "cv:  sklearn.cross_validation.StratifiedKFold(labels=[u'cons' u'cons' u'cons' ..., u'libs' u'libs' u'libs'], n_folds=5, shuffle=False, random_state=None)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to Twitter API\n",
      "def connect_to_API():\n",
      "    \"\"\"\n",
      "    Create instance of tweepy API class with OAuth keys and tokens.\n",
      "    \"\"\"\n",
      "    # initialize tweepy api object with auth, OAuth\n",
      "    TWITTER_API_KEY=os.environ.get('TWITTER_API_KEY')\n",
      "    TWITTER_SECRET_KEY=os.environ.get('TWITTER_SECRET_KEY')\n",
      "    TWITTER_ACCESS_TOKEN=os.environ.get('TWITTER_ACCESS_TOKEN')\n",
      "    TWITTER_SECRET_TOKEN=os.environ.get('TWITTER_SECRET_TOKEN')\n",
      "\n",
      "    auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_SECRET_KEY, secure=True)\n",
      "    auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_SECRET_TOKEN)\n",
      "    api = tweepy.API(auth, cache=None) #removed wait_on_rate_limit=True, wait_on_rate_limit_notify=True\n",
      "\n",
      "    return api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get user timeline by user id\n",
      "def get_timeline(api, uid, count):\n",
      "    \"\"\"Get n number of tweets by passing in user id and number of statuses.\n",
      "        If user has protected tweets, returns [] rather than break the program.\n",
      "    \"\"\"\n",
      "    timeline_list = []\n",
      "    \n",
      "    try:\n",
      "        timeline = tweepy.Cursor(api.user_timeline, id=uid).items(count)\n",
      "        for status in timeline:\n",
      "            timeline_list.append(status)\n",
      "        return timeline_list\n",
      "\n",
      "    except tweepy.TweepError as e:\n",
      "        print e.message[0][\"error\"]\n",
      "        return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get all text from user's timeline, store in list\n",
      "def extract_text(statuses):\n",
      "    \"\"\"\n",
      "    Extract text from a given twitter user's timeline and\n",
      "    append to list.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    Statuses: the new twitter user's timeline, a python object\n",
      "    containing status objects, as tweepy object\n",
      "\n",
      "    Output:\n",
      "    -------\n",
      "    List of statuses' text fields.\n",
      "    \"\"\"\n",
      "    text_list = []\n",
      "\n",
      "    for status in statuses:\n",
      "        status = status._json\n",
      "        text = status[\"text\"]\n",
      "        text_list.append(text)\n",
      "\n",
      "    return text_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_tweets_by_query(api, query, max_tweets):\n",
      "    \"\"\"\n",
      "    Get {max_tweets} tweets labeled by a particular hashtag {query} from Twitter Search API\n",
      "\n",
      "    Parameters:\n",
      "    ----------\n",
      "    Api: the Tweepy API instance.\n",
      "    Query: hashtag to search for, as a string, prefixed by \"#\"\n",
      "    Max_tweets: the total number of tweets requested.\n",
      "\n",
      "    Output:\n",
      "    ------\n",
      "    List of JSON statuses\n",
      "\n",
      "    Note:\n",
      "    ----\n",
      "    Per 15 minutes, app can make 450 requests.\n",
      "    Number of tweets per page defaults to 15. \"Count\" maximum is 100.\n",
      "\n",
      "    \"\"\"\n",
      "    searched_tweets = []\n",
      "\n",
      "    max_id = -1\n",
      "\n",
      "    while len(searched_tweets) < max_tweets:\n",
      "        count = max_tweets - len(searched_tweets)\n",
      "        try:\n",
      "            new_tweets = api.search(q=query, count=count, include_entities=True,\n",
      "             max_id=str(max_id - 1))\n",
      "            if not new_tweets:\n",
      "                break\n",
      "\n",
      "            for tweet in new_tweets:\n",
      "                tweet = tweet._json\n",
      "                searched_tweets.append(tweet)\n",
      "\n",
      "            max_id = new_tweets[-1].id\n",
      "            since_id = new_tweets[0].id\n",
      "\n",
      "            print \"max_id:\", max_id\n",
      "            print \"since_id\", since_id\n",
      "\n",
      "        except tweepy.TweepError as e:\n",
      "            # depending on TweepError.code, one may want to retry or wait\n",
      "            # to keep things simple, we will give up on an error\n",
      "            break\n",
      "    return searched_tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "api = connect_to_API()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tcot = model.Status.get_cons_statuses()\n",
      "tcot_list = []\n",
      "print len(tcot)\n",
      "for status in tcot:\n",
      "    tcot_list.append(status.text)\n",
      "\n",
      "johnoliver = get_timeline(api, \"iamjohnoliver\", 100)\n",
      "text = extract_text(johnoliver)\n",
      "print len(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3000\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = makeVector.transform(text)\n",
      "print sample"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 7548)\t0.251583636133\n",
        "  (0, 7287)\t0.276597697022\n",
        "  (0, 7184)\t0.181888132006\n",
        "  (0, 6740)\t0.317483094995\n",
        "  (0, 6594)\t0.340396919325\n",
        "  (0, 6227)\t0.331260164706\n",
        "  (0, 6090)\t0.340396919325\n",
        "  (0, 4254)\t0.242213572416\n",
        "  (0, 2989)\t0.368778271447\n",
        "  (0, 1242)\t0.317483094995\n",
        "  (0, 47)\t0.298976276659\n",
        "  (1, 8005)\t0.403575197528\n",
        "  (1, 7724)\t0.476168241738\n",
        "  (1, 7037)\t0.388836666345\n",
        "  (1, 3400)\t0.331112219551\n",
        "  (1, 471)\t0.591237355442\n",
        "  (2, 7833)\t0.533842792913\n",
        "  (2, 6730)\t0.353307133108\n",
        "  (2, 4881)\t0.433949765782\n",
        "  (2, 3400)\t0.298969390932\n",
        "  (2, 2530)\t0.559008806919\n",
        "  (3, 7714)\t0.382411031508\n",
        "  (3, 7557)\t0.321119692952\n",
        "  (3, 3829)\t0.404588163825\n",
        "  (3, 3400)\t0.263461815608\n",
        "  :\t:\n",
        "  (95, 6522)\t0.464730946691\n",
        "  (95, 4300)\t0.503478925568\n",
        "  (95, 3400)\t0.269270869906\n",
        "  (95, 2357)\t0.503478925568\n",
        "  (95, 605)\t0.45225688367\n",
        "  (96, 6098)\t0.272938507047\n",
        "  (96, 5887)\t0.70121297636\n",
        "  (96, 4922)\t0.357576803237\n",
        "  (96, 3039)\t0.261703694747\n",
        "  (96, 2943)\t0.344568526637\n",
        "  (96, 933)\t0.344568526637\n",
        "  (97, 7184)\t0.22746727925\n",
        "  (97, 4312)\t0.723094862238\n",
        "  (97, 1732)\t0.461190013484\n",
        "  (97, 1297)\t0.461190013484\n",
        "  (98, 7832)\t0.442571253382\n",
        "  (98, 6190)\t0.381011849555\n",
        "  (98, 5887)\t0.381011849555\n",
        "  (98, 5862)\t0.291810483511\n",
        "  (98, 5421)\t0.343561119914\n",
        "  (98, 3218)\t0.422647140876\n",
        "  (98, 2204)\t0.284399211459\n",
        "  (98, 2007)\t0.226029883213\n",
        "  (99, 7312)\t0.837535629897\n",
        "  (99, 7184)\t0.546382712623\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction = clf.predict(sample)\n",
      "print prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'cons' u'libs' u'libs' u'libs' u'cons' u'libs' u'cons' u'cons' u'cons'\n",
        " u'cons' u'libs' u'cons' u'libs' u'cons' u'libs' u'libs' u'libs' u'cons'\n",
        " u'libs' u'cons' u'libs' u'libs' u'cons' u'cons' u'cons' u'cons' u'libs'\n",
        " u'cons' u'libs' u'libs' u'libs' u'cons' u'cons' u'libs' u'libs' u'libs'\n",
        " u'libs' u'libs' u'libs' u'libs' u'libs' u'libs' u'libs' u'libs' u'libs'\n",
        " u'cons' u'libs' u'cons' u'libs' u'libs' u'libs' u'cons' u'cons' u'libs'\n",
        " u'libs' u'libs' u'libs' u'cons' u'cons' u'cons' u'libs' u'libs' u'cons'\n",
        " u'libs' u'cons' u'cons' u'libs' u'cons' u'libs' u'cons' u'libs' u'libs'\n",
        " u'libs' u'libs' u'cons' u'cons' u'cons' u'cons' u'libs' u'cons' u'libs'\n",
        " u'cons' u'libs' u'libs' u'libs' u'libs' u'cons' u'cons' u'libs' u'libs'\n",
        " u'cons' u'libs' u'cons' u'cons' u'cons' u'cons' u'libs' u'libs' u'libs'\n",
        " u'libs']\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = 0\n",
      "for label in prediction:\n",
      "    if label == \"cons\":\n",
      "        score = score + 0\n",
      "    else:\n",
      "        score = score + 1\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "58\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs=clf.feature_log_prob_[1]\n",
      "print probs\n",
      "\n",
      "# probability= clf.predict_proba(X)\n",
      "# print probability"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-8.39688948 -9.69503513 -9.69503513 ..., -8.98449797 -8.98449797\n",
        " -8.98449797]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score = clf.score(X, y)\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.982833333333\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = makeVector.get_feature_names()\n",
      "len(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "8153"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(zip(probs,features), reverse=True)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[(-4.4435972906539494, u'p2'),\n",
        " (-4.6078735763327945, u'http'),\n",
        " (-4.7656453440301529, u'rt'),\n",
        " (-4.9852179602915276, u'repgutierrez'),\n",
        " (-5.0275581083277645, u'obama'),\n",
        " (-5.0349140724198342, u'immigration'),\n",
        " (-5.2404920016753289, u'president'),\n",
        " (-5.4233188548540845, u'speech'),\n",
        " (-5.6092885725961468, u'latism'),\n",
        " (-5.6243388305729631, u'republicans')]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}